import spacy
import pandas as pd
from rich.text import Text, Style
from file_io import File
from rich import print
from nouns_table import NounsCache
from verbs_table import VerbsCache
from adjectives_table import AdjectivesCache
from adverbs_table import AdverbsCache
from prepositions_table import PrepositionsCache
from multiprocessing import Process, Manager
from rich.table import Table
from time import sleep
from anki_generator import AnkiGenerator

# TODO: if noun not found try lemma and try decomposing it <corrector>
# TODO: create an entity TEXTANALYZER that holds everything
# TODO: Status when all operations are done

# colors dict
colors_definitions = {
    'Bg': "#282828",
    'White': "#fbf1c7",
    'Green': "#b8bb26",
    'Blue': "#08f9e4",
    'Red': "#fe0606",
    'Undefined': "#fabd2f",
    'ADJ': '#baf808',
    'ADP': '#0996b4',
    'ADV': '#e296b4',
    'AUX': '#fc04b7',
    'CONJ': '#0fbed8',
    'CCONJ': '#fa6b97',
    'DET': '#f1d367',
    'INTJ': '#f1d367',
    'NOUN': '#08f9e4',
    'NUM': '#d9ced6',
    'PART': None,
    'PRON': '#f9c602',
    'PROPN': '#f9c602',
    'PUNCT': '#d9ced6',
    'SCONJ': None,
    'SYM': '#d9ced6',
    'VERB': '#fe0606',
    'X': '#d9ced6',
    'SPACE': None
}

INPUT_PATH = "./texts/input_5.txt"


# TODO: must be joined
def run_in_background(func, *args, **kwargs):
    process = Process(target=func, args=args, kwargs=kwargs)
    process.start()


class Blackboard:
    def __init__(self, input_path):
        # create a multiprocessing manager
        manager = Manager()
        self.manager = manager.dict()

        self.manager['text'] = ""
        # dataframe
        self.manager['analyzed_text'] = None

        # caches
        self.manager['noun_cache'] = NounsCache()
        self.manager['verb_cache'] = VerbsCache()
        self.manager['adjective_cache'] = AdjectivesCache()
        self.manager['adverb_cache'] = AdverbsCache()
        self.manager['preposition_cache'] = PrepositionsCache()

        stages = manager.dict()
        stages['input_read'] = None
        stages['analyzed_input'] = None
        stages['analyzed_nouns'] = None
        stages['analyzed_verbs'] = None
        stages['analyzed_adjectives'] = None
        stages['analyzed_adverbs'] = None
        stages['analyzed_prepositions'] = None
        stages['correction'] = None

        # stages: None - 'started' - 'done'
        self.manager['stages'] = stages

        self.read_input(input_path)
        deck_name = input_path.split('/')[-1]
        self.anki_generator = AnkiGenerator(deck_name)

    def read_input(self, input_path):
        self.manager['stages']['input_read'] = 'STARTED'
        with File(input_path, "r") as f:
            self.manager['text'] = f.getData()
            self.manager['stages']['input_read'] = 'DONE'

    def analyze_verbs(self):
        self.manager['stages']['analyzed_verbs'] = 'STARTED'
        verbs_list = self.manager['analyzed_text'].loc[(self.manager['analyzed_text']['pos_'] == 'VERB'), 'text'].tolist()
        for verb in verbs_list:
            self.manager['verb_cache'][verb]
        self.manager['verb_cache'].cache()
        self.manager['stages']['analyzed_verbs'] = 'DONE'

    def analyze_nouns(self):
        self.manager['stages']['analyzed_nouns'] = 'STARTED'
        # trigger meaning parsing for all nouns
        self.manager['analyzed_text'].loc[self.manager['analyzed_text']['pos_'] == 'NOUN', 'text'] = \
            self.manager['analyzed_text'].loc[self.manager['analyzed_text']['pos_'] == 'NOUN', 'text'].replace('-', '')
        nouns_list = self.manager['analyzed_text'].loc[(self.manager['analyzed_text']['pos_'] == 'NOUN'), 'text'].tolist()
        for noun in nouns_list:
            self.manager['noun_cache'][noun]
        self.manager['noun_cache'].cache()
        self.manager['stages']['analyzed_nouns'] = 'DONE'

    def analyze_adjectives(self):
        self.manager['stages']['analyzed_adjectives'] = 'STARTED'
        adjectives_list = self.manager['analyzed_text'].loc[(self.manager['analyzed_text']['pos_'] == 'ADJ'), 'text'].tolist()
        for adjective in adjectives_list:
            self.manager['adjective_cache'][adjective]
        self.manager['adjective_cache'].cache()
        self.manager['stages']['analyzed_adjectives'] = 'DONE'

    def analyze_adverbs(self):
        self.manager['stages']['analyzed_adverbs'] = 'STARTED'
        adverbs_list = self.manager['analyzed_text'].loc[(self.manager['analyzed_text']['pos_'] == 'ADV'), 'text'].tolist()
        for adverb in adverbs_list:
            self.manager['adverb_cache'][adverb]
        self.manager['stages']['analyzed_adverbs'] = 'DONE'

    def analyze_prepositions(self):
        self.manager['stages']['analyzed_prepositions'] = 'STARTED'
        prepos_ = ['CONJ', 'CCONJ', 'SCONJ', 'INTJ', 'ADP', 'X']
        prepositions_list = self.manager['analyzed_text'].loc[self.manager['analyzed_text']['pos_'].isin(prepos_), 'text'].tolist()
        for preposition in prepositions_list:
            self.manager['preposition_cache'][preposition]
        self.manager['preposition_cache'].cache()
        self.manager['stages']['analyzed_prepositions'] = 'DONE'

    def anki_generation(self):
        pass

    def analyze_text(self):
        self.manager['stages']['analyzed_input'] = 'STARTED'
        nlp = spacy.load("de_core_news_sm")
        doc = nlp(self.manager['text'])
        data = []
        for token in doc:
            data.append([token.text,
                         token.lemma_,
                         token.pos_,
                         spacy.explain(token.pos_),
                         token.morph.get("Case"),
                         token.morph.get("Gender"),
                         token.morph.get("Number"),
                         token.morph.get("Person"),
                         token.morph.get("PronType"),
                         token.tag_,
                         token.dep_,
                         token.shape_,
                         token.is_alpha,
                         token.is_stop,
                         token.morph.to_dict()])

        columns = ['text',
                   'lemma_',
                   'pos_',
                   'pos_meaning_',
                   'morph_case',
                   'morph_gender',
                   'morph_number',
                   'morph_person',
                   'morph_prontype',
                   'tag_',
                   'dep_',
                   'shape_',
                   'is_alpha',
                   'is_stop',
                   'all_morph']

        self.manager['analyzed_text'] = pd.DataFrame(data=data, columns=columns)
        self.manager['analyzed_text']['color'] = colors_definitions['White']
        self.manager['analyzed_text']['highlight'] = False

        # fill the meta data Case, Gender, Number, Person
        df = self.manager['analyzed_text']
        df['meta'] = df['morph_case'].apply(lambda x: x.copy())
        df.apply(lambda row: row['meta'].extend(row['morph_gender']), axis=1)
        df.apply(lambda row: row['meta'].extend(row['morph_number']), axis=1)
        df.apply(lambda row: row['meta'].extend(row['morph_person']), axis=1)
        self.manager['analyzed_text'] = df
        self.manager['stages']['analyzed_input'] = 'DONE'

        run_in_background(self.analyze_nouns)
        run_in_background(self.analyze_verbs)
        run_in_background(self.analyze_adjectives)
        run_in_background(self.analyze_adverbs)
        run_in_background(self.analyze_prepositions)
        #run_in_background(self.corrector)
        run_in_background(self.anki_generation)

    def get_analysed_text(self):
        while self.manager['analyzed_text'] is None:
            sleep(1)
        return self.manager['analyzed_text']


# TODO: work on this
blackboard = Blackboard()
print(blackboard.manager['stages'])
blackboard.read_input(INPUT_PATH)
print(blackboard.manager['stages'])
blackboard.analyze_text()
print(blackboard.manager['stages'])
ANALYZED_TEXT = blackboard.get_analysed_text()

noun_cache = blackboard.manager['noun_cache']
verb_cache = blackboard.manager['verb_cache']
adjective_cache = blackboard.manager['adjective_cache']
adverb_cache = blackboard.manager['adverb_cache']
preposition_cache = blackboard.manager['preposition_cache']


def colorize_text(df, scheme=None):
    # reset eveything
    df['color'] = colors_definitions['White']
    df['highlight'] = False

    if scheme == "VERB":
        df.loc[df['pos_'] == scheme, 'color'] = colors_definitions[scheme]
        df.loc[df['pos_'] == "AUX", 'color'] = colors_definitions[scheme]
        df.loc[df['pos_'] == scheme, 'highlight'] = True
        df.loc[df['pos_'] == "AUX", 'highlight'] = True

    elif scheme == "NOUN":
        df.loc[df['pos_'] == scheme, 'color'] = colors_definitions["Undefined"]
        df.loc[(df['pos_'] == 'NOUN') & (df['morph_gender'].apply(lambda x: x == ['Masc'])),
               'color'] = colors_definitions["Green"]
        df.loc[(df['pos_'] == 'NOUN') & (df['morph_gender'].apply(lambda x: x == ['Fem'])),
               'color'] = colors_definitions["Red"]
        df.loc[(df['pos_'] == 'NOUN') & (df['morph_gender'].apply(lambda x: x == ['Neut'])),
               'color'] = colors_definitions["Blue"]
        # highlight
        df.loc[(df['pos_'] == 'NOUN'), 'highlight'] = True

    elif scheme == "ADJ":
        df.loc[df['pos_'] == scheme,
                 ['highlight', 'color']] = [True, colors_definitions[scheme]]

    elif scheme == "ADV":
        df.loc[df['pos_'] == scheme,
                 ['highlight', 'color']] = [True, colors_definitions[scheme]]

    elif scheme == "PREP":
        df.loc[df['pos_'].isin(['CONJ', 'CCONJ', 'SCONJ', 'INTJ', 'ADP', 'X']),
                 ['highlight', 'color']] = [True, colors_definitions['CONJ']]

    else:
        df['color'] = df.apply(lambda x: colors_definitions[x['pos_']], axis=1)

    return df


# build rich text with colors
def generate_rich_text(df, width=30):
    text = Text()
    text.no_wrap = False
    text_width = 0
    for index, row in df.iterrows():
        if row['text'] == '\n':
            text.append('\n')
            text_width = 0
            continue

        if text_width >= width:
            text.append('\n')
            text_width = 0

        if index != 0 and row['pos_'] != 'PUNCT' and text_width != 0:
            text.append(" ")
            text_width += 1

        style = Style(color=row['color'])
        text.append(row['text'], style=style)
        text_width += len(row['text'])

        if row['highlight']:
            # meta
            text.append(" ")
            text_width += 1
            style = Style(color=colors_definitions['Bg'],
                          bgcolor=colors_definitions["White"],
                          dim=True)
            text.append(f" {''.join(row['meta'])} ", style=style)
            text_width += len(''.join(row['meta']))

            # lemma_
            style = Style(color=row['color'],
                          bgcolor=colors_definitions["White"],
                          reverse=True,
                          dim=True)
            text.append(f" {row['lemma_']} ", style=style)
            text_width += len(row['lemma_'])
    return text


def generate_rich_analysis(df, group='NOUN', row_nbr=5):
    # map [group: [select part of meaning, select cache, tags]]
    map = {'NOUN': ['nouns', noun_cache, ['NOUN']],
           'ADJ': ['adjectives_or_adverbs', adjective_cache, ['ADJ']],
           'ADV': ['adjectives_or_adverbs', adverb_cache, ['ADV']],
           'PREP': ['examples', preposition_cache, ['CONJ', 'CCONJ', 'SCONJ', 'INTJ', 'ADP', 'X']],
           }
    tables = []
    nouns_list = df.loc[(df['pos_'].isin(map[group][2])), 'text'].tolist()
    nouns_list = list(set(nouns_list))

    cache = map[group][1]

    for element in nouns_list:
        df = cache[element]
        df.fillna(value="None", inplace=True)
        english_text = cache[element][map[group][0]]['english']
        german_text = cache[element][map[group][0]]['german']

        noun_details = cache[element]['noun_details']['english'].split('\n')

        if len(noun_details) > 2 and group == 'NOUN':
            noun_gender = noun_details[2]
        else:
            noun_gender = "None"

        english_text = english_text.split('\n')
        german_text = german_text.split('\n')

        gender_styles = {
            'genus: MASC': colors_definitions['Green'],
            'genus: FEMI': colors_definitions['Red'],
            'genus: NEUT': colors_definitions['Blue']
        }

        style = gender_styles.get(noun_gender, colors_definitions['White'])

        table = Table(title=f"{element}", style=style, header_style=style, title_style=style)
        table.add_column("English", justify="left", style=style, no_wrap=True)
        table.add_column("German", justify="left", style=style,no_wrap=True)
        for eng, ger in zip(english_text[:row_nbr], german_text[:row_nbr]):
            table.add_row(eng, ger)
        tables.append(table)
    return tables


def generate_rich_analysis_verb(df, row_nbr=5):
    tables = []
    verbs_list = df.loc[(df['pos_'] == 'VERB'), 'text'].tolist()
    lemmas_list = df.loc[(df['pos_'] == 'VERB'), 'lemma_'].tolist()

    verbs_list = list(set(verbs_list))
    lemmas_list = list(set(lemmas_list))

    for verb, lemma in zip(verbs_list, lemmas_list):
        df = noun_cache[verb]
        df.fillna(value="None", inplace=True)
        english_text = noun_cache[verb]['verbs']['english']
        german_text = noun_cache[verb]['verbs']['german']

        english_text = english_text.split('\n')
        german_text = german_text.split('\n')

        table = Table(title=f"{verb}")
        table.add_column("English", justify="left", no_wrap=True)
        table.add_column("German", justify="left", no_wrap=True)
        for eng, ger in zip(english_text[:row_nbr], german_text[:row_nbr]):
            table.add_row(eng, ger)
        tables.append(table)
        conj_tables = verb_cache[verb]['indicative_active']
        conj_tables.fillna(value="None", inplace=True)
        table = Table()
        table.add_column("Present", justify="left", no_wrap=False)
        table.add_column("Imperfect", justify="left", no_wrap=False)
        table.add_column("Perfect", justify="left", no_wrap=False)
        table.add_column("Future", justify="left", no_wrap=False)
        if all(val != "None" for val in conj_tables.values):
            table.add_row(conj_tables['Present'],
                          conj_tables['Imperfect'],
                          conj_tables['Perfect'],
                          conj_tables['Future'])
        else:
            conj_tables = verb_cache[lemma]['indicative_active']
            conj_tables.fillna(value="None", inplace=True)
            table.add_row(conj_tables['Present'],
                          conj_tables['Imperfect'],
                          conj_tables['Perfect'],
                          conj_tables['Future'])

        tables.append(table)
    return tables


if __name__ == "__main__":
    df = colorize_text(ANALYZED_TEXT, 'NOUN')
    print(generate_rich_analysis(df)[0])
    print(blackboard.manager['stages'])

